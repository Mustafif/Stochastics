% !TeX program = xelatex
\documentclass[11pt, letterpaper]{article}
\title{MTH500 Assignment 1}
\author{Mustafif Khan}
\date{\today}
\input{include/structure}
\usepackage{pdfpages}

\begin{document}
\begin{titlepage}
	\centering
	\vspace*{1cm}
	\LARGE\textbf{MTH 500 Assignment 1}

	\vspace{1.5cm}
	\Large\textbf{Mustafif Khan | 501095413 | Section 11}

	\vspace{1.5cm}
	\large\textit{Mustafif Khan is solely responsible for its content.}
\end{titlepage}

\newpage
\section{Introduction}

In this comprehensive report, I will expound on my solutions to the seven
challenging questions in our Mathematical Statistics assignment. These
questions delve into a broad range of topics we have studied in our course,
including but not limited to random variables, probability distributions, time
series, Markov chains, and Poisson processes.

To tackle each question, I employed different approaches and utilized various
tools such as MATLAB, R, Python, or Excel, performing calculations,
simulations, estimations, comparisons, and interpretations as deemed necessary.

I have included detailed supporting materials such as graphs, tables, formulas,
and explanations whenever required to ensure that my solutions are easy to
grasp. These materials serve to exemplify the steps taken in solving the
problems and the reasoning behind my solutions.

\section{Objectives}

The main goals of this report are threefold:

\subsection{Demonstrate Understanding}
The first objective is to demonstrate my understanding of the concepts and
methods we've learned in our Mathematical Statistics course. I aim to show how
I've applied these concepts and methods to solve complex problems by presenting
my solutions to the assignment questions.

\subsection{Showcase Problem-Solving Skills}
The second objective is to showcase my problem-solving skills. This involves
using different tools and techniques to solve problems involving random
variables, probability distributions, time series, Markov chains, and Poisson
processes. By detailing the steps I took in solving each problem, I aim to show
how I approached each problem and how I used the tools at my disposal.

\subsection{Communicate Effectively}
The third objective is communicating my results and reasoning effectively. This
involves using graphs, tables, formulas, and explanations to support my
answers. I aim to make my solutions clear and easily understood by presenting
these supporting materials.

\newpage

\includepdf{q1_1}
\includepdf{q1_2}

\newpage
\subsection*{D)}
The signal $X_t$ is a stationary process both in the strict and wide sense.
This is because:

\begin{itemize}
	\item The mean function is constant and equal to $0$ regardless of $t$.

	\item The variance function is constant regardless of $t$.
	\item The autocovariance function $\gamma (t, t+h)$ only depends on
	      $h$, not on
	      $t$.
	\item The autocorrelation function $\rho (t, t+h)$ also only depends on
	      $h$ not on
	      $t$. It is equal to $\frac{\gamma (t, t+h)}{\sigma^2(t)}$
\end{itemize}

\includepdf{q2_1}
\includepdf{q2_2}
\includepdf{q3}

\newpage
\section*{Question 4}
\subsection*{A)}
To simulate a moving average process with $\theta = \cfrac{k}{10}$ driven by a
Gaussian
white noise, I created the R code \verb|q4a.r| where defined our parameters,
\verb|n| to define the number
of observations which I set to $1000$, \verb|theta| which is set to $0.3$ since
$k=3$. Lastly as defined
in the question, we set the variable \verb|sigma| to $1$. To generate the
Gaussian white noise, I use the
\verb|rnorm| function which uses the normal distribution and is randomized to
simulate the white noise. To intialize
the moving average process, we use the \verb|rep| function which replicates
elements of a list, we set this from $0$ to \verb|n|.
After we create a loop to define each \verb|t| in the moving average process
using the formula given. After
we plot our function.

\begin{file}[q4a.r]
	\lstinputlisting[language=r]{code/q4a.r}
\end{file}
\begin{center}
	\includegraphics[scale=0.47]{code/q4a}
\end{center}

\subsection*{B)}
To simulate the moving average process with t-distribution with 4 degrees of
freedom, we will set similar
parameters like A), with $n=1000$, $theta = 0.3$, and $df=4$, After to generate
the randomized t-distribution,
we will use the \verb|rt| function with \verb|n| and \verb|df=df|. After we
will intialize and define the moving
average process like we had done before, and after we will plot our simulated
values.

\begin{file}[q4b.r]
	\lstinputlisting[language=r]{code/q4b.r}
\end{file}

\begin{center}
	\includegraphics[scale=0.47]{code/q4b}
\end{center}
\newpage
\subsection*{C)}

\begin{file}[q4c.r]
	\lstinputlisting[language=r]{code/q4c.r}
\end{file}

The provided R code sets up a moving average process of order $1$ with Gaussian
noise, calculates the empirical autocorrelation of the process at different
lags, and plots the autocorrelation function. The
empirical autocorrelation function is calculated as the ratio of the covariance
between the series at time $t$ and $t + h$ and the variance of the series. The
plot
shows the autocorrelation values for each lag from $0$ to $10$. The term $\rho
	X(1)$
represents the autocorrelation of the process at lag 1, indicating how much the
current value of the process depends on its previous value. For a moving
average process of order $1$.

\begin{center}
	\includegraphics[scale=0.4]{code/q4c}
\end{center}

\subsection*{D)}

\begin{equation*}
	\begin{split}
		\mu &= 0\\
		\sigma^2 &= 1 + \theta^2\\
		&= 1 + (\cfrac{k}{10})^2\\
		&= 1 + \cfrac{9}{100} \\
		&= \cfrac{109}{100} \\
		\rho(h) &= \cfrac{\theta}{1 + \theta^2}\\
		&= \cfrac{9}{100} * \cfrac{100}{109}\\
		&= \cfrac{9}{109}
	\end{split}
\end{equation*}

\subsection*{E)}
The moving average $X_t$ is a stationary process in the wide sense, but not in
the strict sense.
This is because:

\begin{itemize}
	\item The mean function is contant and equal to zero, regardless of
	      $t$.
	\item The variance function is contant, regardless of $t$.
	\item The autocovariance function $\gamma (t, t+h)$ only depends on
	      $h$, not on
	      $t$.
	\item The autocorrelation function $\rho (t, t+h)$ also only depends on
	      $h$ not on
	      $t$. It is equal to $\frac{\gamma (t, t+h)}{\sigma^2(t)}$
\end{itemize}

However, the moving average $X_t$ is not strictly stationary because the joint
distribution of any finite number of observations changes with time. For
example, the distribution of $(X_t, X_{t+1})$ is different from the
distribution of
$(X_{t+1}, X_{t+2})$, since the former has a nonzero covariance while the
latter has a
zero covariance.
\newpage
\section*{Question 5}

For question 5, I solved the problem by utilizing Python classes to handle
finding each subsection of this question
so I can present the final answers in a complete table. To answer each
subsection I will provide the snippet of the python
file \verb|q5.py| that corresponds with finding the said problem. At the end
once the code is shown, I will present the
results in a neat table. The reason I chose to use a Python class is because
all of the poisson files were identical,
which means I would be able to handle the repetitive tasks effectively.

\subsection*{i)}
First we need to be able to load the data and estimate our $\lambda$ value. To
begin in our code, we will be using the
\verb|pandas| library to read an excel file and use the second column which
contains the arrivals. We will need to be able
to calculate the poisson distribution, so we will need to make use of the
\verb|scipy| library, and lastly for better
numerical capabilities we will be using the \verb|numpy| library.

We will be creating a class called \verb|PoissonData| and to create a new
instance of it, we will define a constructor
which will take in a file name, we will read it use the first column which will
be assigned to the \verb|arrivals| field,
then we will take the mean of the arrivals and that will be our $\lambda$
estimate and used later we will set $\mu$ to 30.
This can all be seen below:

\begin{file}[q5.py i)]
	\lstinputlisting[linerange={1-10},language=python]{code/q5.py}
\end{file}

\subsection*{ii)}

To calculate the probability of  arrivals that occur in the interval of 5
hours, we will first calculate the rate
which is found by $\lambda * \frac{5}{24}$ then to get the probability we use
the Poisson PMF from $0$ to our rate.
This is all calculated in our function \verb|no_arrivals_5_hours_prob| in the
\verb|PoissonData| class:

\begin{file}[q5.py ii)]
	\lstinputlisting[language=python, linerange={11-14}]{code/q5.py}
\end{file}

\subsection*{iii)}
To calculate the probability of at least one arrival occurs, we will be needing
to find $1-Poisson(0,\lambda)$ as
shown in the function \verb|at_least_one_arrival_prob| in the
\verb|PoissonData| class:

\begin{file}[q5.py iii)]
	\lstinputlisting[language=python, linerange={15-18}]{code/q5.py}
\end{file}

\subsection*{iv)}
To calculate the mean and variance of the arrival in a day, we need to remember
that in a Poisson distribution,
$E(X) = \lambda$ and $Var(X) = \lambda$, so in our \verb|mean_arrivals| and
\verb|variance_arrivals| functions, we
return our \verb|lambdaHat| field.

\begin{file}[q5.py]
	\lstinputlisting[language=python, linerange={19-24}]{code/q5.py}
\end{file}

\subsection*{v)}
To calculate the average and standard deviation of the total time it takes
for a patient in a single day using $\mu = 30$ is by multiplying \verb|self.mu|
by the mean
of arrivals and standard deviation respectively. This can be seen below:

\begin{file}[q5.py]
	\lstinputlisting[language=python, linerange={25-30}]{code/q5.py}
\end{file}
\noindent P.D.F over time: 
\begin{equation}
	\begin{split}
		P(y \geq x) &= f(x;k, \lambda)P(N_t = k)\\
		&= \cfrac{\lambda^{k}x^{k-1}e^{-\lambda x}}{(k - 1)!} * e^{-\lambda^t} * \cfrac{(\lambda t)^k}{k!}
	\end{split}
\end{equation}

\subsection*{Results}
To get the results for each file, I did add an extra method to turn our results
into strings where each
result from i)\dots v) would be rounded to 4 decimal points. I created a
\verb|results.txt| file where each of the results
were appended and in a \verb|for| loop all files from $0\dots 9$ were
calculated.

\begin{file}[q5.py]
	\lstinputlisting[language=python, linerange={31-58}]{code/q5.py}
\end{file}

Instead of showing a $100$ line text file, I opted to neatly format it into a
table where we get our
results for each file:

\begin{table}[h]
	\centering
	\small
	\begin{tabular}{|l|c|c|c|c|c|c|c|}
		\hline
		File    & $\lambda$ & Prob. No 5 Hrs   & Prob. At Least One &
		Mean    & Variance  & Avg. Time (mins) & Std. Dev. (mins)
		\\
		\hline
		poissn0 & 3.0606    & 0.5285           & 0.9531             &
		3.0606  & 3.0606    & 91.8182
		        & 58.4208
		\\
		poissn1 & 2.9596    & 0.5398           & 0.9482             &
		2.9596  & 2.9596    & 88.7879
		        & 49.5958
		\\
		poissn2 & 2.9293    & 0.5432           & 0.9466             &
		2.9293  & 2.9293    & 87.8788
		        & 42.4810
		\\
		poissn3 & 2.9394    & 0.5421           & 0.9471             &
		2.9394  & 2.9394    & 88.1818
		        & 54.1797
		\\
		poissn4 & 3.1111    & 0.5230           & 0.9554             &
		3.1111  & 3.1111    & 93.3333
		        & 47.5094
		\\
		poissn5 & 3.2121    & 0.5121           & 0.9597             &
		3.2121  & 3.2121    & 96.3636
		        & 54.5941
		\\
		poissn6 & 3.1515    & 0.5186           & 0.9572             &
		3.1515  & 3.1515    & 94.5455
		        & 51.8489
		\\
		poissn7 & 3.0000    & 0.5353           & 0.9502             &
		3.0000  & 3.0000    & 90.0000
		        & 50.1630
		\\
		poissn8 & 3.3131    & 0.5015           & 0.9636             &
		3.3131  & 3.3131    & 99.3939
		        & 52.0757
		\\
		poissn9 & 3.2121    & 0.5121           & 0.9597             &
		3.2121  & 3.2121    & 96.3636
		        & 51.1192
		\\
		\hline
	\end{tabular}
	\caption{Poisson Data Results}
\end{table}
\newpage
\section*{Question 6}
The timeseries data we will be analyzing is the Apple stock price found in
\verb|AAPL.csv|, to solve each
part we will be using R in the file \verb|q6.r|.
\subsection*{i)}
To plot the Apple time series we will need to read the \verb|csv| file, get the
daily returns from the \verb|Change| column,
then we need to convert each of the strings into numerical numbers, we also get
the stock prices from the \verb|Price| column.
With the \verb|daily_returns| and \verb|prices| variables, we will create a
dataframe with the daily returns as the x-axis
and prices as the y-axis. Lastly we plot the prices as a scatterplot:

\begin{file}[q6.r i)]
	\lstinputlisting[language=r, linerange={1-34}]{code/q6.r}
\end{file}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.55]{code/q6-1.png}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.55]{code/q6-2.png}
\end{figure}
\newpage

\subsection*{ii)}
To calculate the first four moments (mean, standard deviation, skewness and
kurtosis) for the prices,
and daily returns, we will need to use the functions \verb|mean|, \verb|sd|,
\verb|skewness| and \verb|kurtosis|
respectively for the variables \verb|prices| and \verb|dailyReturns| that were
calculated previously.

\begin{file}[q6.r ii)]
	\lstinputlisting[language=r, linerange={37-55}]{code/q6.r}
\end{file}

\noindent When we run our script we get the following result:

\begin{verbatim}
Mean of prices: 120.4879 
Standard deviation of prices: 41.64585 
Skewness of prices: 0.5805278 
Kurtosis of prices: 2.611525 

Mean of daily returns: 0.06097975 
Standard deviation of daily returns: 1.58414 
Skewness of daily returns: -0.4705426 
Kurtosis of daily returns: 8.834479 
\end{verbatim}

\subsection*{iii)}
Lastly to plot the empirical p.d.f against the Gaussian p.d.f, we first need to
find the kernel density
estimate to find the empirical p.d.f using the \verb|density| function on
\verb|dailyReturns|. After we can
plot the kernel density estimate using \verb|plot|. To compute the Gaussian
p.d.f, we need a sequence which
will go from the minimum value of our \verb|dailyReturns| to the max. Next we
use the sequence to calculate
the p.d.f using \verb|dnorm| with our mean and standard deviation of the dail
returns. With our
x values and p.d.f, we can add it to the plot using \verb|lines| and a legend
to better understand
which p.d.f is which.

\begin{file}[q6.r iii)]
	\lstinputlisting[language=r, linerange={58-75}]{code/q6.r}
\end{file}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.55]{code/q6-2.png}
\end{figure}

\section*{Question 7}
In Question 7 I had to use Markov Chains to estimate the one-step transition
probability matrix for the
file \verb|mchdata3.xlsx|. This was done using Python, and begins with needing
to use the \verb|numpy| and
\verb|pandas| library and reading the file as shown:

\begin{file}[q7.py (initialization)]
	\lstinputlisting[language=python, linerange={1-5}]{code/q7.py}
\end{file}

Next we store all of the weather states from \verb|data| into the variable
\verb|weather_states| by slicing
the values from the second column and returning a list. In the problem they say
that each weather state is represented
as the following:

\begin{itemize}
	\item Sunny = $1$
	\item Cloudy = $2$
	\item Rainy = $3$
\end{itemize}

These are all declared in the variable \verb|states| as the array
\verb|[1, 2, 3]|, with this variable
we are able to intialize our transition matrix by creating a 3x3 matrix of
zeros (using \verb|len(states)|).
To calculate the transition counts we use a \verb|for| loop that iterates
through \verb|weather_states| from
the first element to the last. Inside of the loop, we declare the
\verb|from_state| to be the current element in
\verb|weather_states| and \verb|to_state| to be the next element. After we
store the result into the \verb|transition_matrix|.

After we calculate the transition counts, we need to calculate the transition
probabilities by diving the
transition matrix by the sum of each row in the matrix to obtain the
probabilities. We store these
results in a new matrix called \verb|transition_probabilities|. After we can
print out each of the
transition probabilities from one state to the other.

\begin{file}[q7.py (rest)]
	\lstinputlisting[language=python, linerange={7-25}]{code/q7.py}
\end{file}

When we run the code we get the following results:
\begin{verbatim}
	Transition Probabilities:
	From State 1:
	  To State 1: Probability = 0.78
	  To State 2: Probability = 0.22
	  To State 3: Probability = 0.00
	From State 2:
	  To State 1: Probability = 0.51
	  To State 2: Probability = 0.14
	  To State 3: Probability = 0.35
	From State 3:
	  To State 1: Probability = 0.00
	  To State 2: Probability = 0.77
	  To State 3: Probability = 0.23	
\end{verbatim}

Since we need to find the transition from state 1 to state 1, then that means
the probability that if Friday was sunny, what is the chance Sunday is sunny is
$78\%$.
\newpage
\section*{Conclusion}

In this assignment, I have applied various concepts and methods of mathematical
statistics and stochastic processes to analyze different types of data and
problems. I have learned how to:

\begin{itemize}
	\item Identify and verify the properties of stationary processes, such
	      as mean,
	      variance, and autocorrelation functions. I have used these properties to
	      determine whether a given signal or a moving average process is stationary in
	      the strict or wide sense, and to explain the implications of stationarity for
	      data analysis.
	\item Calculate and interpret the joint, marginal, and conditional
	      distributions of
	      random variables, as well as their moments and correlation coefficients. I have
	      used these distributions to find probabilities, expectations, and covariances
	      of different events and variables. I have also used them to compare the
	      dependence and independence of random variables.
	\item Estimate the parameters of Poisson processes and exponential
	      distributions
	      using empirical data. I have used these parameters to model the arrival and
	      service times of patients in an emergency hospital unit. I have also used them
	      to find the probabilities, means, variances, and densities of different
	      quantities related to the Poisson process.
	\item Simulate and compare moving average processes with different types of
	      noises,
	      such as Gaussian and t-student. I have used R/Python to generate samples of
	      these processes and to plot their graphs. I have also computed their empirical
	      autocorrelation functions and compared them with their theoretical values. I
	      have learned how different noises affect the behavior and characteristics of
	      the moving average processes.
	\item Select and graph a time series of daily prices and returns. I have
	      plotted the
	      graphs of the daily prices and returns, and computed their first four moments.
	      I have also compared the empirical probability density function of the returns
	      with a Gaussian density function with the same mean and standard deviation. I
	      have evaluated the normality and autocorrelation of the time series using
	      graphical and numerical methods.
	\item Estimate the transition probability matrix of a Markov chain using
	      weather
	      data, and predict the future state of the chain. I have used the data in file
	      \verb|mchdata3.xslx| to estimate the one-step transition probabilities between
	      three
	      states: sunny, cloudy, and rainy. I have used these probabilities to find the
	      probability that Sunday is a sunny day given that Friday is a sunny day.
\end{itemize}

Through this assignment, I have improved my skills in programming, data
analysis, and statistical inference. I have also gained a deeper understanding
of the applications and limitations of stochastic models in real-world
situations. I have learned how to use stochastic models to describe, explain,
predict, and simulate various phenomena involving uncertainty and randomness.

\end{document}